---
title: "Assignment-5"
author: "Ashvitha Mothakani"
date: "17/04/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Importing all the libraries

```{r}
library(cluster)
library(factoextra)
library(caret)
library(knitr)
library(dendextend)

#Importing  the dataset
Cereals_Dataset<- read.csv("C:/Users/mashv/Downloads/Cereals.csv")
Data_Cereals_Dataset <- data.frame(Cereals_Dataset[,4:16])


#processing the missed data

Data_Cereals_Dataset <- na.omit(Data_Cereals_Dataset)

#Data Normalization
Cereals_normalization <- scale(Data_Cereals_Dataset)

#Applying hierarchical clustering to the data using Euclidean distance to the normalize measurements.

Distance <- dist(Cereals_normalization, method = "euclidean")
hierarchial.clusterer_complete <- hclust(Distance, method = "complete")

#Plotting the dendogram
plot(hierarchial.clusterer_complete, cex = 0.7, hang = -1)


#Using agnes function to perfrom clustering with single linkage, complete linkage, average linkage and Ward.
hierarchial.cluster_single <- agnes(Cereals_normalization, method = "single")
hierarchial.cluster_complete <- agnes(Cereals_normalization, method = "complete")
hierarchial.cluster_average <- agnes(Cereals_normalization, method = "average")
hierarchial.cluster_ward <- agnes(Cereals_normalization, method = "ward")

#Comparing single Linkage vs Complete Linkage vs Average Linkage vs Ward Linkage
print(hierarchial.cluster_single$ac)
print(hierarchial.cluster_complete$ac)
print(hierarchial.cluster_average$ac)
print(hierarchial.cluster_ward$ac)

#Since WARD method has the highest value of 0.9046042, we will consider it.
 
#2. Choosing the clusters

pltree(hierarchial.cluster_ward, cex = 0.7, hang = -1, main = "Dendrogram of agnes (Using Ward)")
rect.hclust(hierarchial.cluster_ward, k = 5, border = 1:4)
Cluster1 <- cutree(hierarchial.cluster_ward, k=5)
dataframe2 <- as.data.frame(cbind(Cereals_normalization,Cluster1))

#We will take 5 clusters after seeing the distance.

#Creating  the Partitions

set.seed(123)
Partition1 <- Data_Cereals_Dataset[1:50,]
Partition2 <- Data_Cereals_Dataset[51:74,]

#Performing Hierarchial Clustering,consedering k = 5.

AG_single <- agnes(scale(Partition1), method = "single")
AG_complete <- agnes(scale(Partition1), method = "complete")
AG_average <- agnes(scale(Partition1), method = "average")
AG_ward <- agnes(scale(Partition1), method = "ward")
cbind(single=AG_single$ac , complete=AG_complete$ac , average= AG_average$ac , ward= AG_ward$ac)
pltree(AG_ward, cex = 0.6, hang = -1, main = "Dendogram of Agnes with Partitioned Data (Using Ward)")
rect.hclust(AG_ward, k = 5, border = 1:4)

cut_2 <- cutree(AG_ward, k = 5)

#Calculating the centeroids.
result <- as.data.frame(cbind(Partition1, cut_2))
result[result$cut_2==1,]

centroid_1 <- colMeans(result[result$cut_2==1,])
result[result$cut_2==2,]

centroid_2 <- colMeans(result[result$cut_2==2,])
result[result$cut_2==3,]

centroid_3 <- colMeans(result[result$cut_2==3,])
result[result$cut_2==4,]

centroid_4 <- colMeans(result[result$cut_2==4,])
centroids <- rbind(centroid_1, centroid_2, centroid_3, centroid_4)

x2 <- as.data.frame(rbind(centroids[,-14], Partition2))

#Calculating the Distance

Distance_1 <- get_dist(x2)
Matrix_1 <- as.matrix(Distance_1)
dataframe1 <- data.frame(data=seq(1,nrow(Partition2),1), Clusters = rep(0,nrow(Partition2)))
for(i in 1:nrow(Partition2)) 
{dataframe1[i,2] <- which.min(Matrix_1[i+4, 1:4])}
dataframe1
cbind(dataframe2$Cluster1[51:74], dataframe1$Clusters)
table(dataframe2$Cluster1[51:74] == dataframe1$Clusters)

# From the above output, We can say that  model is partially stable as we are getting 12 FALSE and 12 TRUE 

#3) The elementary public schools would like to choose a set of Cereals_Dataset to include in their daily cafeterias.
#Every day a different cereal is offered, but all Cereals_Dataset should support a healthy diet. 
#For this goal, you are requested to find a cluster of “healthy Cereals_Dataset.” 
#Clustering Healthy Cereals_Dataset.

Healthy_Cereals_Dataset <- Cereals_Dataset
Healthy_Cereals_Dataset_new <- na.omit(Healthy_Cereals_Dataset)
HealthyClust <- cbind(Healthy_Cereals_Dataset_new, Cluster1)
HealthyClust[HealthyClust$Cluster1==1,]
HealthyClust[HealthyClust$Cluster1==2,]
HealthyClust[HealthyClust$Cluster1==3,]
HealthyClust[HealthyClust$Cluster1==4,]
#Mean ratings to determine the best cluster.
mean(HealthyClust[HealthyClust$Cluster1==1,"rating"])
mean(HealthyClust[HealthyClust$Cluster1==2,"rating"])
mean(HealthyClust[HealthyClust$Cluster1==3,"rating"])
mean(HealthyClust[HealthyClust$Cluster1==4,"rating"])

#We can consider cluster 1 as the highest since mean ratings are high.
```